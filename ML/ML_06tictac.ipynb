{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bac8822-987a-4914-a8e9-fc290aa4830a",
   "metadata": {},
   "source": [
    "Practical No: 6\n",
    "Build a Tic-Tac-Toe game using reinforcement learning in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4143612c-022a-44c7-9c98-d00df6a82d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5ce6d5-76e7-4089-9a97-1f5aced59c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the Tic-Tac-Toe environment and rules\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [' ' for _ in range(9)]\n",
    "        self.current_winner = None\n",
    "\n",
    "    def print_board(self):\n",
    "        for row in [self.board[i*3:(i+1)*3] for i in range(3)]:\n",
    "            print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "    def available_moves(self):\n",
    "        return [i for i, spot in enumerate(self.board) if spot == ' ']\n",
    "\n",
    "    def empty_squares(self):\n",
    "        return ' ' in self.board\n",
    "\n",
    "    def make_move(self, square, letter):\n",
    "        if self.board[square] == ' ':\n",
    "            self.board[square] = letter\n",
    "            if self.winner(square, letter):\n",
    "                self.current_winner = letter\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def winner(self, square, letter):\n",
    "        # Check row\n",
    "        row_ind = square // 3\n",
    "        row = self.board[row_ind*3:(row_ind+1)*3]\n",
    "        if all([s == letter for s in row]):\n",
    "            return True\n",
    "        # Check column\n",
    "        col_ind = square % 3\n",
    "        col = [self.board[col_ind+i*3] for i in range(3)]\n",
    "        if all([s == letter for s in col]):\n",
    "            return True\n",
    "        # Check diagonals\n",
    "        if square % 2 == 0:\n",
    "            diagonal1 = [self.board[i] for i in [0,4,8]]\n",
    "            diagonal2 = [self.board[i] for i in [2,4,6]]\n",
    "            if all([s == letter for s in diagonal1]) or all([s == letter for s in diagonal2]):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [' ' for _ in range(9)]\n",
    "        self.current_winner = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4bfff5-1bdf-4d92-8333-dedf865d8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Q-Learning agent for AI\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.3, gamma=0.9, epsilon=0.2):\n",
    "        self.q_table = defaultdict(lambda: np.zeros(9))\n",
    "        self.alpha = alpha    # Learning rate\n",
    "        self.gamma = gamma    # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "\n",
    "    def get_state(self, game):\n",
    "        return ''.join(game.board)\n",
    "\n",
    "    def choose_action(self, game):\n",
    "        state = self.get_state(game)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(game.available_moves())\n",
    "        else:\n",
    "            q_values = self.q_table[state]\n",
    "            max_q = max([q_values[a] for a in game.available_moves()])\n",
    "            max_actions = [a for a in game.available_moves() if q_values[a] == max_q]\n",
    "            return random.choice(max_actions)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        future = 0 if done else max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.alpha * (reward + self.gamma * future - self.q_table[state][action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b0e040-b821-4467-bcae-81e6ca5c73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train the AI by playing multiple games against random moves\n",
    "def train(agent, episodes=10000):\n",
    "    game = TicTacToe()\n",
    "    for _ in range(episodes):\n",
    "        game.reset()\n",
    "        state = agent.get_state(game)\n",
    "        done = False\n",
    "        while not done:\n",
    "            # AI move\n",
    "            action = agent.choose_action(game)\n",
    "            game.make_move(action, 'X')\n",
    "            next_state = agent.get_state(game)\n",
    "            \n",
    "            if game.current_winner == 'X':\n",
    "                agent.learn(state, action, 1, next_state, True)\n",
    "                done = True\n",
    "            elif not game.empty_squares():\n",
    "                agent.learn(state, action, 0.5, next_state, True)\n",
    "                done = True\n",
    "            else:\n",
    "                # Random opponent move\n",
    "                opponent_action = random.choice(game.available_moves())\n",
    "                game.make_move(opponent_action, 'O')\n",
    "                next_state_op = agent.get_state(game)\n",
    "                if game.current_winner == 'O':\n",
    "                    agent.learn(state, action, -1, next_state_op, True)\n",
    "                    done = True\n",
    "                else:\n",
    "                    agent.learn(state, action, 0, next_state_op, False)\n",
    "                    state = next_state_op\n",
    "\n",
    "# Initialize and train the agent\n",
    "agent = QLearningAgent()\n",
    "train(agent, episodes=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f40ac3-ec4c-4153-962d-5298eb7c3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Play the game interactively with human input\n",
    "def print_board_positions():\n",
    "    print(\"Board positions (0-8):\")\n",
    "    for row in [[str(i+j*3) for i in range(3)] for j in range(3)]:\n",
    "        print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "def play_human_vs_ai(agent):\n",
    "    game = TicTacToe()\n",
    "    print_board_positions()\n",
    "    game.print_board()\n",
    "    \n",
    "    while game.empty_squares():\n",
    "        # AI move\n",
    "        action = agent.choose_action(game)\n",
    "        game.make_move(action, 'X')\n",
    "        print(\"\\nAI's move:\")\n",
    "        game.print_board()\n",
    "        if game.current_winner == 'X':\n",
    "            print(\"AI wins!\")\n",
    "            return\n",
    "        if not game.empty_squares():\n",
    "            print(\"It's a tie!\")\n",
    "            return\n",
    "\n",
    "        # Human move\n",
    "        valid_move = False\n",
    "        while not valid_move:\n",
    "            try:\n",
    "                human_move = input(\"Enter your move (0-8): \")\n",
    "                if human_move.lower() == 'exit':\n",
    "                    print(\"Game exited.\")\n",
    "                    return\n",
    "                human_move = int(human_move)\n",
    "                if human_move in game.available_moves():\n",
    "                    game.make_move(human_move, 'O')\n",
    "                    valid_move = True\n",
    "                else:\n",
    "                    print(\"Invalid move! Position already taken or out of range.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input! Enter a number between 0 and 8.\")\n",
    "        \n",
    "        print(\"\\nYour move:\")\n",
    "        game.print_board()\n",
    "        if game.current_winner == 'O':\n",
    "            print(\"You win!\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876b850b-13ca-4e57-ac25-baeb5a42c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board positions (0-8):\n",
      "| 0 | 1 | 2 |\n",
      "| 3 | 4 | 5 |\n",
      "| 6 | 7 | 8 |\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "\n",
      "AI's move:\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "|   |   | X |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| O |   |   |\n",
      "|   |   |   |\n",
      "|   |   | X |\n",
      "\n",
      "AI's move:\n",
      "| O |   |   |\n",
      "|   |   | X |\n",
      "|   |   | X |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| O |   | O |\n",
      "|   |   | X |\n",
      "|   |   | X |\n",
      "\n",
      "AI's move:\n",
      "| O |   | O |\n",
      "| X |   | X |\n",
      "|   |   | X |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid move! Position already taken or out of range.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| O | O | O |\n",
      "| X |   | X |\n",
      "|   |   | X |\n",
      "You win!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Start the interactive game\n",
    "play_human_vs_ai(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c7b0cf-e58c-4645-8af5-95a131d7bea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 wins: 695\n",
      "Agent 2 wins: 222\n",
      "Draws: 83\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TicTacToeEnvironment:\n",
    "    def __init__(self):\n",
    "        self.state = [0] * 9  # 0 = empty, 1 = X, -1 = O\n",
    "        self.is_terminal = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [0] * 9\n",
    "        self.is_terminal = False\n",
    "\n",
    "    def get_available_moves(self):\n",
    "        return [i for i, mark in enumerate(self.state) if mark == 0]\n",
    "\n",
    "    def make_move(self, move, player_mark):\n",
    "        if self.is_terminal:\n",
    "            raise ValueError(\"Game is already over.\")\n",
    "        if self.state[move] != 0:\n",
    "            raise ValueError(f\"Cell {move} is not empty.\")\n",
    "        self.state[move] = player_mark\n",
    "\n",
    "    def check_win(self, player_mark):\n",
    "        winning_states = [\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8],  # rows\n",
    "            [0, 3, 6],\n",
    "            [1, 4, 7],\n",
    "            [2, 5, 8],  # columns\n",
    "            [0, 4, 8],\n",
    "            [2, 4, 6],  # diagonals\n",
    "        ]\n",
    "        for idxs in winning_states:\n",
    "            if all(self.state[i] == player_mark for i in idxs):\n",
    "                self.is_terminal = True\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_draw(self):\n",
    "        if 0 not in self.state:\n",
    "            self.is_terminal = True\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, learning_rate=0.9, discount_factor=0.9, exploration_rate=0.3):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.q_table = np.zeros((3**9, 9), dtype=np.float32)\n",
    "\n",
    "    def get_state_index(self, state):\n",
    "        state_index = 0\n",
    "        for i, mark in enumerate(state):\n",
    "            state_index += (3**i) * (mark + 1)\n",
    "        return state_index\n",
    "\n",
    "    def choose_action(self, state, available_moves):\n",
    "        state_index = self.get_state_index(state)\n",
    "\n",
    "        # Îµ-greedy policy\n",
    "        if np.random.random() < self.exploration_rate:\n",
    "            return int(np.random.choice(available_moves))\n",
    "\n",
    "        q_values = self.q_table[state_index, available_moves]\n",
    "        best_idx_in_subset = int(np.argmax(q_values))\n",
    "        return available_moves[best_idx_in_subset]\n",
    "\n",
    "    def update_q_table(self, state, action, next_state, reward):\n",
    "        state_index = self.get_state_index(state)\n",
    "        if next_state is None:\n",
    "            max_next_q = 0.0\n",
    "        else:\n",
    "            next_state_index = self.get_state_index(next_state)\n",
    "            max_next_q = float(np.max(self.q_table[next_state_index]))\n",
    "\n",
    "        current_q = self.q_table[state_index, action]\n",
    "        target = reward + self.discount_factor * max_next_q\n",
    "        self.q_table[state_index, action] = (\n",
    "            1 - self.learning_rate\n",
    "        ) * current_q + self.learning_rate * target\n",
    "\n",
    "\n",
    "def evaluate_agents(agent1, agent2, num_episodes=1000):\n",
    "    env = TicTacToeEnvironment()\n",
    "    agent1_wins = agent2_wins = draws = 0\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        env.reset()\n",
    "        current_agent = agent1  # agent1 = X (+1), agent2 = O (-1)\n",
    "\n",
    "        while not env.is_terminal:\n",
    "            available_moves = env.get_available_moves()\n",
    "            current_state = env.state.copy()\n",
    "\n",
    "            action = current_agent.choose_action(current_state, available_moves)\n",
    "            env.make_move(action, 1 if current_agent is agent1 else -1)\n",
    "\n",
    "            # Check terminal outcomes\n",
    "            if env.check_win(1 if current_agent is agent1 else -1):\n",
    "                current_agent.update_q_table(current_state, action, None, 10.0)\n",
    "                if current_agent is agent1:\n",
    "                    agent1_wins += 1\n",
    "                else:\n",
    "                    agent2_wins += 1\n",
    "                break\n",
    "\n",
    "            if env.is_draw():\n",
    "                current_agent.update_q_table(current_state, action, None, 0.0)\n",
    "                draws += 1\n",
    "                break\n",
    "\n",
    "            next_state = env.state.copy()\n",
    "            current_agent.update_q_table(current_state, action, next_state, 0.0)\n",
    "\n",
    "            # Switch agent\n",
    "            current_agent = agent2 if current_agent is agent1 else agent1\n",
    "\n",
    "    return agent1_wins, agent2_wins, draws\n",
    "\n",
    "\n",
    "# Create and evaluate agents\n",
    "agent1 = QLearningAgent()\n",
    "agent2 = QLearningAgent()\n",
    "\n",
    "agent1_wins, agent2_wins, draws = evaluate_agents(agent1, agent2, num_episodes=1000)\n",
    "\n",
    "print(f\"Agent 1 wins: {agent1_wins}\")\n",
    "print(f\"Agent 2 wins: {agent2_wins}\")\n",
    "print(f\"Draws: {draws}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4de30f-cb3c-4801-8476-babcfa16dfad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
